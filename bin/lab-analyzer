#!/usr/bin/env bash
#
# testbed/cluster discovery and validation
# 	1. Discover cluster_type, num_workers and num_cpus (per worker)
# 	2. Confim the user-intent workers specified in lab.config.
#
# Usage: lab-analyzer -o <out-file>
#

set -euo pipefail

OUTPUT_FILE=""
while [[ $# -gt 0 ]]; do
    case "$1" in
        --output|-o)
            OUTPUT_FILE="$2"
            shift 2
            ;;
        *)
            echo "Unknown argument: $1" >&2
            exit 1
            ;;
    esac
done

if [[ -z "$OUTPUT_FILE" ]]; then
    echo "[ERROR] Missing required --output argument" >&2
    exit 1
fi


auto_fix="true"

source ${REG_ROOT}/lab.config

# About $reg_dir,
# On controller, the user can create REGULUS somewhere under their home i.e /root/path/regulus
# On bastion, the user can be root or kni. Since regulus will clone a repo there. it wil be /home/kni/path/regulus or /root/path/regulus.
# We need to identify the relative path from the bastion user's HOME. That is the "path/regulus" so that we can ssh to the bastion and cd to "path/regulus"
reg_dir="${PWD#"$HOME"/}"
echo reg_dir=$reg_dir >&2

if [ "$(hostname)" == "$REG_OCPHOST" ] ; then
    iam="bastion"
else
    iam="local"
fi

# We compute the number of CPUs for each pod based on the node.allocatable.cpu.
# We learn this value during during lab-analyzer time, and this value can go down
# when we install additional k8s services/features i,.e SRIOV and PAO. Hence
# we "reserve" some CPUs for it one time. We have seen 4 was not enough sometime.
# Hence use 8.
RESERVED_CPUS=10

# Define the JSON content
tb_info='{
    "CLUSTER_TYPE":			"value1",
    "NUM_WORKERS": 			"value3",
    "ALLOCATABLE_CPUS": 	"value3",
    "USEABLE_CPUS": 		"value3",
    "CORE_PERSOCKET": 		"value3"
}'

function exit_error() {
    local msg
    msg="$1"
    echo "[ERROR] ${msg}" 1>&2
    exit 1
}

script_dir="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
core_auth_script_path="${script_dir}/core-auth-key.sh"

SSH_OPTS="-o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -o LogLevel=ERROR -o ConnectTimeout=20"
SSH_OPTS+="${extra_SSH_OPTS:-}"

# compare two IDs for match. They can be FQDN or IP in any combination.
hostids_match() {
    local host1="$1"
    local host2="$2"

    # Helper to get IPs from DNS or literal IPs
    resolve_ips() {
        local input="$1"
        # If it's already an IP, return it
        if [[ "$input" =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
            echo "$input"
        else
            getent ahosts "$input" | awk '{print $1}' | sort -u
        fi
    }

    # Helper to get local IPs. These are extra interfaces setup by jetlag perhaps. dig does not know them.
    local_ips() {
        ip -4 -o addr show | awk '{print $4}' | cut -d/ -f1 | sort -u
    }

    # Resolve
    ips1=$(resolve_ips "$host1")
    ips2=$(resolve_ips "$host2")

    # Add local IPs if either input refers to the local machine
    hostname_fqdn=$(hostname -f)
    hostname_short=$(hostname)

    if [[ "$host1" == "$hostname_fqdn" || "$host1" == "$hostname_short" ]]; then
        ips1=$(local_ips)
    fi
    if [[ "$host2" == "$hostname_fqdn" || "$host2" == "$hostname_short" ]]; then
        ips2=$(local_ips)
    fi

    # Compare all IPs
    for ip1 in $ips1; do
        for ip2 in $ips2; do
            if [[ "$ip1" == "$ip2" ]]; then
                return 0
            fi
        done
    done
    return 1
}

function do_ssh() {
    local user_host="$1"
    shift
    #local ssh_opts="-o StrictHostKeyChecking=no -o PasswordAuthentication=no"
    local user host ssh_cmd

    # Parse user and host from user_host
    user=$(echo "$user_host" | awk -F@ '{print $1}')
    host=$(echo "$user_host" | awk -F@ '{print $2}')

    # Check if user and host are valid
    if [ -z "$user" ] || [ -z "$host" ]; then
        echo "Error: Invalid user/host: $user_host" >&2
        return 1
    fi

    # Create the ssh command with the given commands
    ssh_cmd="ssh $SSH_OPTS $user_host \"bash -c '$@'\""

    # Echo the command for debugging
    echo "($iam) CMD: $ssh_cmd" >&2

    # Execute the command
    eval $ssh_cmd
    local rc=$?
    return $rc
}

function f_verify_lab_config {
echo IN: f_verify_lab_config  >&2
    # Verify a few common missed setup activities.
    #   REG_KNI_USER (root vs kni)
    #   All export vars (most likely b/c user forgot to fixup lab.config)
    #   SRIOV-config (user has not invoked "make init") - we can do it, but let the user do it.
    #   PAO-config (user has not invoked "make init")

    local DEST="$REG_KNI_USER@$REG_OCPHOST"
    #workers=$(ssh $DEST "oc get nodes --selector='node-role.kubernetes.io/worker' -o jsonpath='{.items[*].metadata.name}'")
    workers=$(do_ssh $DEST "source $reg_dir/lab.config &&  oc get nodes --request-timeout=30s --selector='node-role.kubernetes.io/worker' -o jsonpath='{.items[*].metadata.name}'")

    if [ $? -ne 0 ] ; then
        echo "Cannot ssh to bastion $DEST" >&2
        exit 1
    fi
    if [[ !  "$workers" == *"$OCP_WORKER_0"* ]]; then
        echo "OCP_WORKER_0=$OCP_WORKER_0 is NOT in '$workers'"  >&2
        echo "Check lab.config on both sides"  >&2
        exit 1
    fi
    if [[ !  "$workers" == *"$OCP_WORKER_1"* ]]; then
        echo "OCP_WORKER_1=$OCP_WORKER_1 is NOT in '$workers'"  >&2
        echo "Check lab.config on both sides"  >&2
        exit
    fi
    if [[ !  "$workers" == *"$OCP_WORKER_2"* ]]; then
        echo "OCP_WORKER_2=$OCP_WORKER_2 is NOT in '$workers'"  >&2
        echo "Check lab.config on both sides"  >&2
        exit 1
    fi

    # Check lab.config consistency
    # ssh + grep has too much syntax headaches. scp and then grep local is easier.
    scp $DEST:$reg_dir/lab.config /tmp/lab.config
    rem_exports=$(grep export /tmp/lab.config | grep -v '#')

    local_exports=$(cd $REG_ROOT && cat lab.config | grep export | grep -v '#')
    if [ "$rem_exports" != "$local_exports" ]; then
        if [ "$auto_fix" == "true" ]; then
            echo "WARN: $reg_dir/lab.config file on controller differs the one on the bastion" >&2
            echo "auto_fix is ON. Fixing it"  >&2
            scp $REG_ROOT/lab.config  $DEST:$REG_ROOT/lab.config
        else
            echo "ERROR: $reg_dir/lab.config file on controller differs the one on the bastion" >&2
        fi
    fi

    # The bastion also needs init-lab (for CLUSTER_TYPE) before we can init SRIOV/UNIV/
    if [ "$auto_fix" == "true" ]; then
        echo "$LINENO bastion CMD: ssh $DEST cd $reg_dir && source bootstrap.sh && make init-lab" >&2
        #ssh $DEST "cd $reg_dir && source bootstrap.sh && make init-lab"
        do_ssh $DEST "cd $reg_dir && source bootstrap.sh && make init-lab"
    fi

    # Check SRIOV-config and PAO-config ready on the bastion
    if ! do_ssh "$DEST" "cd $reg_dir && source bootstrap.sh && cd SRIOV-config/ && ls setting.env" >/dev/null 2>&1 ; then
        if [ "$auto_fix" == "true" ]; then
            echo "WARN: SRIOV-config/UNIV is not yet initialized on the bastion" >&2
            echo "auto_fix is ON. Fixing it"  >&2
            #(do_ssh $DEST "cd $reg_dir && source bootstrap.sh && cd SRIOV-config/UNIV && make init")
            do_ssh $DEST "cd $reg_dir && source bootstrap.sh && cd SRIOV-config/UNIV && make init"
        else
            echo "ERROR: SRIOV-config/UNIV is not yet initialized on the bastion" >&2
            echo "Hint: go to $reg_dir/SRIOV-config/UNIV on the bastion and 'make init'" >&2
            exit 1
        fi
    fi

    if ! do_ssh "$DEST" "cd $reg_dir && source bootstrap.sh && cd SRIOV-config/ && ls setting.env" >/dev/null 2>&1 ; then
        if [ "$auto_fix" == "true" ]; then
            echo "WARN: PAO-config is not yet initialized on the bastion" >&2
            echo "auto_fix is ON. Fixing it"  >&2
            (do_ssh $DEST "cd $reg_dir && source bootstrap.sh && cd PAO-config/ && make init")

        else
            echo "ERROR: PAO-config is not yet initialized on the bastion" >&2
            echo "Hint: go to $reg_dir/PAO-config on the bastion and 'make init'" >&2
            exit 1
        fi
    fi

    echo "Lab config check done " >&2
    return
}

updated_json="{}"
function f_update_tb_info {
	# Read the JSON file
	json=$tb_info
	updated_json=$(echo "$json" | jq ".CLUSTER_TYPE = \"$tb_cluster_type\" | .NUM_WORKERS = \"$tb_num_workers\" \
								|     .ALLOCATABLE_CPUS = \"$tb_alloc_cpus\" |  .USEABLE_CPUS = \"$tb_useable_cpus\" \
                                |     .CORE_PERSOCKET = \"$tb_cps\"")
	# Write the JSON content to a file
	echo "$updated_json" 
}

function f_get_cluster_type {
	# number of node is 1 or 3 or more
	num_node="$(do_ssh $REG_KNI_USER@$REG_OCPHOST "source $reg_dir/lab.config && kubectl get nodes --no-headers" | wc -l)"
	case $num_node in
		1)
			echo "SNO"
			;;
		3)
			echo "COMPACT"
			;;
		*)
			echo "STANDARD"
			;;
	esac
}

function f_validate_worker_nodes {
	workers="$(do_ssh $REG_KNI_USER@$REG_OCPHOST "source $reg_dir/lab.config && kubectl get nodes --no-headers --selector=node-role.kubernetes.io/worker=")"
	tb_num_workers=$(echo "$workers" | wc -l)
	worker_names=$(echo "$workers" | awk '{print $1}')
	#echo names=$worker_names
	# verify workers in lab.conf
	if [[ "$worker_names" != *"$OCP_WORKER_0"* ]]; then
		echo "Please correct OCP_WORKER_0=\"$OCP_WORKER_0\" var in lab.config. Worker nodes are $worker_names" >&2
		exit 1
	fi
	if [[ "$worker_names" != *"$OCP_WORKER_1"* ]]; then
		echo "Please correct OCP_WORKER_1=\"$OCP_WORKER_1\" var in lab.config. Worker nodes are $worker_names" >&2
		exit 1
	fi
	if [[ "$worker_names" != *"$OCP_WORKER_2"* ]]; then
		echo "Please correct OCP_WORKER_2=\"$OCP_WORKER_2\" var in lab.config. Worker nodes are $worker_names" >&2
		exit 1
	fi
}

function create_mirror_repo_on_bastion {
    local_repo_path=$(git rev-parse --show-toplevel)
    remote_user=$1
    remote_host=$2

    echo "HN create_mirror_repo_on_bastion on $2 " >&2

    local_basename=$(basename "$REG_ROOT")

    # Get the current branch name from the local repository
    current_branch=$(git branch --show-current)

    # Check if the remote repository already exists
    repo_exists=$(do_ssh ${remote_user}@${remote_host} "[ -d ${reg_dir}/.git ] && echo 'exists' || echo 'not exists'")

    if [ "$repo_exists" = "exists" ]; then
        echo "The repository already exists on the bastion host at ${reg_dir}. No action taken." >&2
        do_ssh ${remote_user}@${remote_host} "rm -fr ${reg_dir}"
    fi
    #else
        echo "The repository does not exist. Creating the repository on the bastion host..."  >&2
 
        # Create the regulus dir on the bastion host
        do_ssh ${remote_user}@${remote_host} "mkdir -p ${reg_dir}"

        # Initialize a non-bare repository on the bastion host
        
        do_ssh ${remote_user}@${remote_host} "cd ${reg_dir} && git init 2>/dev/null"

        # Add the remote repository to local Git config. But remove remote first if there was a old one.
        echo "CMD: git remote remove $local_basename-peer-regulus" >&2
        git remote remove $local_basename-peer-regulus  2>/dev/null  || true
        echo "CMD: git remote add $local_basename-peer-regulus ${remote_user}@${remote_host}:${reg_dir}" >&2


        git remote add $local_basename-peer-regulus ${remote_user}@${remote_host}:${reg_dir} 


        # Push your local repository to the remote/bastion repository
        echo "CMD: git push $local_basename-peer-regulus ${current_branch}"  >&2
        git push $local_basename-peer-regulus ${current_branch}

        # Switch to the current branch on the remote/bastion machine
        echo "CMD: ssh ${remote_user}@${remote_host} cd ${reg_dir} && git checkout ${current_branch}"  >&2
        do_ssh ${remote_user}@${remote_host} "cd ${reg_dir} && git checkout ${current_branch}"

        # finally copy mirror lab.config and jobs.config to remote
        scp lab.config ${remote_user}@${remote_host}:${reg_dir}/
        scp jobs.config ${remote_user}@${remote_host}:${reg_dir}/
        scp makefile ${remote_user}@${remote_host}:${reg_dir}/
        scp bin/lab-analyzer ${remote_user}@${remote_host}:${reg_dir}/bin/

        echo "Repository has been successfully created and mirrored to the bastion host. The branch '${current_branch}' has been checked out."  >&2
    #fi
}

# Function to combine two host strings into a unique array
# Arguments: string1 string2
# Output: global array BM_HOST_ARR
# Notes: string can be both comma separated or space separated tokens
combine_hosts() {
    local str1="$1"
    local str2="$2"

    # Replace commas with spaces
    str1="${str1//,/ }"
    str2="${str2//,/ }"

    # Read into temporary arrays
    read -ra arr1 <<< "$str1"
    read -ra arr2 <<< "$str2"

    # Combine arrays
    local combined=("${arr1[@]}" "${arr2[@]}")

    # Remove duplicates using associative array
    declare -g -A uniq
    BM_HOST_ARR=()
    for host in "${combined[@]}"; do
        if [[ -n "$host" && -z "${uniq[$host]-}" ]]; then
            BM_HOST_ARR+=("$host")
            uniq[$host]=1
        fi
    done
}

# We are running on the Crucible controller. If the bastion is a different host, mirror Regulus repo onto it.
#if [ "$(hostname)" != "$REG_OCPHOST" ] ; then
if ! hostids_match "$(hostname)" "$REG_OCPHOST" ; then
    echo "$0 is NOT on the bastion ... mirror check lab.config match" >&2
    # mirror repo in a sub-shell, to avoid all the unwanted messages
    (
        # Install regulus repo on the bastion if applicable
        create_mirror_repo_on_bastion "${REG_KNI_USER}" "${REG_OCPHOST}"

    ) > lab-init.log 2>&1
    f_verify_lab_config 
else
    echo "$0 is running on the bastion ... skip lab.config match check" >&2
fi

# Mirror Regulus repo on BM_HOSTS and TREX_HOSTS too.
combine_hosts "$BM_HOSTS" "$TREX_HOSTS"

for host in "${BM_HOST_ARR[@]}"; do
    #if [ "$(hostname)" != "$host" ] ; then
    if ! hostids_match "$(hostname)" "$host" ; then
    	if  hostids_match "$REG_OCPHOST" "$host" ; then
            echo "remotehost $host is bastion. Skipping cloning..." >&2
            continue
        fi
        echo "remotehost $host is not bastion. Cloning repo to remotehost" >&2
        # Mirror repo in a sub-shell to avoid unwanted messages
        (
            create_mirror_repo_on_bastion "root" "${host}"
        ) > rem-init.log 2>&1
    fi
done

# check ssh and $reg_dir correctness
if ! do_ssh "$REG_KNI_USER@$REG_OCPHOST" "cd $reg_dir" ; then
	echo "Error: Please confirm REG_KNI_USER and REG_OCPHOST in lab.config" >&2
	exit 1
fi

tb_cluster_type=$(f_get_cluster_type)
echo "cluster_type=$tb_cluster_type" >&2
f_validate_worker_nodes
if [[ -z "$OCP_WORKER_0" ]]; then
    first_worker=$(do_ssh $REG_KNI_USER@$REG_OCPHOST "oc get nodes -l node-role.kubernetes.io/worker= --no-headers -o custom-columns=NAME:.metadata.name | head -1")
else
    first_worker=$OCP_WORKER_0
fi
first_worker_ip="$(do_ssh $REG_KNI_USER@$REG_OCPHOST "source $reg_dir/lab.config && kubectl get node/\$first_worker -o=custom-columns=IP:.status.addresses[0].address --no-headers")"
tb_alloc_cpus="$(do_ssh $REG_KNI_USER@$REG_OCPHOST "source $reg_dir/lab.config && kubectl get node/$first_worker -ojsonpath='{.status.allocatable.cpu}'")"

# Round-down to whole CPU if we see like 31500m
if [[ "$tb_alloc_cpus" == *m ]]; then
    tb_alloc_cpus="${tb_alloc_cpus:0: -4}"
fi

tb_useable_cpus=$(($tb_alloc_cpus-$RESERVED_CPUS))
echo "useable_cpus=$tb_useable_cpus" >&2

# Setup auth key to ssh core@<ip>
if [[ -e "${core_auth_script_path}" ]]; then
  do_ssh $REG_KNI_USER@$REG_OCPHOST "source $reg_dir/lab.config && bash $reg_dir/bin/core-auth-key.sh ${first_worker} ~/.ssh/id_rsa.pub >&2"
else
  echo $LINENO "$core_auth_script_path not found "
  exit 1
fi

# get worker cpu topology
cps_string="$(do_ssh $REG_KNI_USER@$REG_OCPHOST "ssh $SSH_OPTS core@$first_worker_ip lscpu" | grep Core)"
if [ -z "$cps_string" ]; then
    echo "Failed to ssh core@$first_worker_ip. Please setup 'core' login" >&2
    exit 
fi
# extract the number from like "Core(s) per socket:  28"
tb_cps=$(echo "$cps_string" | awk '{print $NF}')
echo "core-per-socket=$tb_cps" >&2 

f_update_tb_info

# write result to out
printf "%s\n" "$updated_json" > "$OUTPUT_FILE"

echo "($iam) $0 completed" >&2

# done
