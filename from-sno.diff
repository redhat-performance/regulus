diff --git a/templates/uperf/run.sh.template b/templates/uperf/run.sh.template
index 7f2bbb7..5913ace 100755
--- a/templates/uperf/run.sh.template
+++ b/templates/uperf/run.sh.template
@@ -13,6 +13,7 @@ source ${REG_ROOT}/templates/common/functions
 DURATION=${DURATION:-0}
 OCP_PROJECT=${OCP_PROJECT:-crucible-rickshaw}
 TPL_QOS=${TPL_QOS:-burstable}
+TPL_NUMCPUS=${TPL_NUMCPUS:-0}
 
 scale_up_factor=$TPL_SCALE_UP_FACTOR # Number of client-server pairs per host/node/node-pair. Consider using even numbers due to NUMA carving
 
@@ -51,6 +52,24 @@ if [ "$(hostname)" == "${REG_OCPHOST}" ]; then
 fi
 k8susr=$REG_KNI_USER # Might be "root" or "kni" for some installations
 
+is_single_numa() {
+    local policy
+    policy=$(do_ssh "$k8susr@$ocphost" \
+        "kubectl get performanceprofile $MCP -o jsonpath='{.spec.numa.topologyPolicy}'")
+    if [ "$policy" == "single-numa-node" ]; then
+        echo "true"
+    else
+        echo "false"
+    fi
+}
+
+get_pp_policy() {
+    do_ssh "$k8susr@$ocphost" \
+        "kubectl get performanceprofile reghwol -o jsonpath='{.spec.numa.topologyPolicy}'" 2>/dev/null \
+        | tr -d '[:space:]'
+}
+
+
 # Start a clean project with privilege 
 do_ssh $k8susr@$ocphost "kubectl delete ns $OCP_PROJECT" &> /dev/null
 do_ssh $k8susr@$ocphost "kubectl create ns $OCP_PROJECT && \
@@ -109,10 +128,17 @@ if [ -f "${TPL_RESOURCES}" ]; then
 else
    resource_file="`/bin/pwd`/resource.json"
 fi
-    
+ 
+is_single_numa() {
+do_ssh $k8susr@$ocphost \
+"kubectl get performanceprofile reghwol -o jsonpath='{if eq .spec.numa.topologyPolicy \"single-numa-node\"}true{else}false{end}{\"\\n\"}'"
+
+}
+
 # Create a resource JSON to size the pods
+cpu=0
 function gen_resource_file() {
-    local cpu=$1
+    cpu=$1
     if [ "$pod_qos" == "static" ]; then
         # static has number of cpu constraints.
         #   1. multiple number of cores i.e. 2,4,6 and cannot be 1,3,5,7 when HT is on
@@ -134,6 +160,12 @@ function gen_resource_file() {
             fi
         fi
 
+        cpu="${TPL_NUMCPUS}"
+        if [ "${cpu}" -lt 2 ]; then
+            echo "ERROR: Not enough CPUs for static CPU allocation"
+            exit 1;
+        fi
+
         echo '"resources": {'     >$resource_file
         echo '    "requests": {' >>$resource_file
         echo '        "cpu": "'$cpu'",' >>$resource_file
@@ -153,8 +185,15 @@ function gen_resource_file() {
     fi
 }
 
+other_tags=""
 collect_more_tags() {
-	if [ "$TPL_SRIOV" == 1 ],; then
+	if [ "$TPL_QOS" == "static" ]; then
+        other_tags+=",qos:${cpu}CPU"
+    else
+        other_tags+=",qos:$TPL_QOS"
+    fi
+
+	if [ "$TPL_SRIOV" == 1 ]; then
         other_tags+=",model:SRIOV"
     elif [ "$TPL_HOSTNETWORK" == 1 ]; then
         other_tags+=",model:HOSTNETWORK"
@@ -278,7 +317,7 @@ for num_pods in $scale_up_factor; do
             # Create a nodeSelector JSON to place pods
             for i in `seq 1 $scale_out_factor`; do
                 for j in 0 $(($nodes_per_client_server-1)); do
-                    if [ "$topo" == "ingress" -o "$topo" == "egress" ]; then
+                    if [ "$topo" == "ingress" -o "$topo" == "egress" -o "$topo" == "intranode" ]; then
                        idx=`echo "($i-1)" | bc`
                     else
                       idx=`echo "($i-1)*2+$j" | bc`
@@ -368,7 +407,8 @@ for num_pods in $scale_up_factor; do
     tags="sdn:$network_type,mtu:$network_mtu,rcos:$rcos,kernel:$kernel,irq:$irq,userenv:$userenv,osruntime:$osruntime"
     tags+=",topo:$topo,pods-per-worker:$num_pods,scale_out_factor:$scale_out_factor"
     if [ "$topo" == "internode" -a "$topo" == "intranode" ]; then
-        tags+=",pod_qos:$pod_qos"
+        #tags+=",pod_qos:$pod_qos"
+        :
     fi
     collect_more_tags
     if [ ! -z "$other_tags" ]; then
