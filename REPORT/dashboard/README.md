# Performance Benchmark Dashboard

A web-based interactive dashboard for visualizing and analyzing performance benchmark reports generated by the Regulus report generation system.

## Features

- **Multi-Report Aggregation**: Load and analyze multiple JSON reports simultaneously
- **Interactive Charts**: Visualize trends, comparisons, and statistics with Chart.js
- **Advanced Filtering**: Filter results by benchmark, model, kernel, topology, and more
- **Trend Analysis**: Track performance metrics over time with time-series charts
- **Configuration Comparison**: Side-by-side comparison of different configurations
- **Top Performers**: Identify best performing configurations
- **Detailed Results Table**: Browse all test results with sorting and pagination
- **Real-time Updates**: Reload reports without restarting the server

## Quick Start

### Prerequisites

- **Python 3.6 or higher**
- **Flask 2.0 or higher**

Install Flask:

```bash
pip install flask

# Verify installation
python3 -c "import flask; print('Flask', flask.__version__, 'installed!')"
```

### Launch the Dashboard

**Method 1: Using makefile (Recommended)**
```bash
cd /path/to/regulus
make report-dashboard
# Dashboard loads reports from REPORT/generated/
```

**Method 2: From REPORT directory**
```bash
cd /path/to/regulus/REPORT
python3 dashboard/run_dashboard.py --reports generated

# Or with custom reports directory:
python3 dashboard/run_dashboard.py --reports /path/to/reports
```

**Method 3: From any directory (absolute path)**
```bash
python3 /full/path/to/REPORT/dashboard/run_dashboard.py --reports /path/to/reports
```

The dashboard will be available at: `http://0.0.0.0:5000` or `http://localhost:5000`

**You'll see output like this:**
```
============================================================
Starting Performance Dashboard
============================================================
Dashboard URL: http://0.0.0.0:5000
Reports directory: /tmp/reports
Template directory: .../dashboard/templates
Static directory: .../dashboard/static
Loaded reports: 3
Total results: 25
============================================================

 * Serving Flask app 'dashboard.dashboard_app'
 * Running on http://0.0.0.0:5000/
```

## Command-Line Options

```bash
python3 dashboard/run_dashboard.py [OPTIONS]

Options:
  --reports DIR    Directory containing JSON report files (default: current directory)
  --host HOST      Host to bind to (default: 0.0.0.0)
  --port PORT      Port to listen on (default: 5000)
  --debug          Enable debug mode (auto-reload on code changes)
  -h, --help       Show help message and exit
```

### Examples

```bash
# Launch with default settings (current directory, port 5000)
python3 dashboard/run_dashboard.py

# Specify custom reports directory
python3 dashboard/run_dashboard.py --reports /data/performance-reports

# Use custom port
python3 dashboard/run_dashboard.py --port 8080

# Bind to localhost only (not accessible from network)
python3 dashboard/run_dashboard.py --host 127.0.0.1

# Enable debug mode for development (auto-reload on file changes)
python3 dashboard/run_dashboard.py --debug

# Combine multiple options
python3 dashboard/run_dashboard.py --reports /data/reports --host 0.0.0.0 --port 8000

# Test with sample data
python3 dashboard/run_dashboard.py --reports . --debug
```

### Testing the Dashboard

After launching, verify it's working:

```bash
# Check if server is running
curl http://localhost:5000/api/summary

# Check process on port 5000
lsof -i :5000

# View all available results
curl http://localhost:5000/api/results | python3 -m json.tool

# Check available filters
curl http://localhost:5000/api/filters
```

## Dashboard Views

### 1. Overview

**Summary Cards**: Quick stats showing total reports, results, benchmarks, and date range

**Performance by Model/Kernel**: Bar charts showing average throughput grouped by model or kernel version

**Top 10 Performers**: Table of highest-performing test configurations

### 2. Trends

**Time-Series Charts**: Visualize performance trends over time

**Grouping Options**:
- No grouping (all results combined)
- Group by Model
- Group by Kernel
- Group by Topology

Useful for tracking performance regression/improvement over time.

### 3. Comparison

**Side-by-Side Comparison**: Compare two configurations directly

**Compare By**:
- Model (e.g., e810 vs e910)
- Kernel (e.g., 5.14 vs 5.15)
- Topology (e.g., linear vs mesh)
- Performance baseline

Shows:
- Mean throughput for each configuration
- Absolute difference
- Percentage change
- Which configuration is better

### 4. Results Table

**Detailed View**: Searchable and sortable table of all test results

**Features**:
- Pagination (25 results per page)
- Search across all fields
- Sort by any column
- Filterable by benchmark, model, kernel, etc.

## Filters

All views support filtering by:

- **Benchmark**: uperf, iperf, trafficgen
- **Model**: Network adapter model (e.g., e810, e910)
- **Kernel**: Kernel version (e.g., 5.14, 5.15)
- **Topology**: Network topology (e.g., linear, mesh)
- **Performance**: Performance baseline (e.g., baseline, tuned)

Filters persist across tab changes and can be cleared with the "Clear Filters" button.

## API Endpoints

The dashboard provides REST API endpoints for programmatic access:

### Summary Statistics
```
GET /api/summary
```
Returns overall summary and benchmark statistics.

### All Results
```
GET /api/results?benchmark=uperf&model=e810
```
Query parameters: `benchmark`, `model`, `kernel`, `topo`, `perf`

### Trend Data
```
GET /api/trends?metric=mean&group_by=model&benchmark=uperf
```
Query parameters: `metric`, `group_by`, `benchmark`

### Configuration Comparison
```
GET /api/compare?field=model&value_a=e810&value_b=e910&metric=mean
```
Query parameters: `field`, `value_a`, `value_b`, `metric`, `benchmark`

### Statistics by Group
```
GET /api/statistics?group_by=model&metric=mean&benchmark=uperf
```
Query parameters: `group_by`, `metric`, `benchmark`

### Top Performers
```
GET /api/top_performers?metric=mean&top_n=10&benchmark=uperf
```
Query parameters: `metric`, `top_n`, `benchmark`, `ascending`

### Available Filters
```
GET /api/filters
```
Returns all available filter values for dropdowns.

### Configuration Matrix
```
GET /api/matrix?field_x=model&field_y=kernel&metric=mean
```
Query parameters: `field_x`, `field_y`, `metric`, `benchmark`

### Reload Reports
```
POST /api/reload
Body: {"reports_dir": "/path/to/reports"}
```
Reload reports from disk without restarting the server.

## Architecture

### Backend (Python/Flask)

- **dashboard_app.py**: Flask web application with REST API endpoints
- **data_loader.py**: Loads and parses JSON reports into BenchmarkResult objects
- **aggregator.py**: Provides analytics (trends, comparisons, statistics)

### Frontend (HTML/JavaScript)

- **templates/dashboard.html**: Main dashboard UI with Bootstrap 5
- **static/dashboard.js**: Interactive charts and API calls using Chart.js

### Data Flow

```
JSON Reports → ReportLoader → BenchmarkResult[] → BenchmarkAggregator → Analytics
                                                  ↓
                                              Flask API → Frontend → Charts/Tables
```

## Development

### Project Structure

```
dashboard/
├── __init__.py              # Package initialization
├── dashboard_app.py         # Flask web application
├── data_loader.py           # Report loading and parsing
├── aggregator.py            # Analytics and aggregation
├── run_dashboard.py         # CLI entry point
├── launch_dashboard         # Bash launcher script
├── static/
│   └── dashboard.js         # Frontend JavaScript
├── templates/
│   └── dashboard.html       # Dashboard UI template
└── README.md                # This file
```

### Adding New Features

**New Metrics**: Add to `BenchmarkResult` in `data_loader.py` and update extraction logic

**New Aggregations**: Add methods to `BenchmarkAggregator` in `aggregator.py`

**New API Endpoints**: Add routes to `DashboardApp._setup_routes()` in `dashboard_app.py`

**New Charts**: Add chart rendering functions to `dashboard.js` and update HTML template

## Dependencies

**Required**:
- Python 3.9+
- Flask (`pip install flask`)

**Frontend (CDN)**:
- Bootstrap 5.3.0
- Chart.js 4.4.0
- jQuery 3.7.0
- DataTables 1.13.6

## Troubleshooting

### Template Not Found Error
```
jinja2.exceptions.TemplateNotFound: dashboard.html
```

**Solution:** The dashboard now uses absolute paths, so this should be fixed. If you still see this error:
- Verify templates exist: `ls dashboard/templates/dashboard.html`
- Check the startup output shows correct paths
- Make sure you're running from the correct directory

### No reports found
- Verify the reports directory contains `.json` files
  ```bash
  ls /tmp/reports/*.json
  ```
- Make sure JSON files are not schema files (`*_schema.json`)
- Check that reports were generated with `make report-summary`

### Dashboard shows "Loaded reports: 0"
- The reports directory is empty or has no JSON files
- Generate reports first:
  ```bash
  cd /path/to/regulus
  make report-summary
  # Outputs to REPORT/generated/report.json
  ```
- Use test data for testing:
  ```bash
  cd REPORT
  python3 dashboard/run_dashboard.py --reports dashboard/test_data
  ```

### Charts not displaying
- Check browser console for JavaScript errors (F12 in most browsers)
- Ensure Chart.js CDN is accessible (requires internet connection)
- Verify API endpoints are returning data:
  ```bash
  curl http://localhost:5000/api/summary
  ```

### Port already in use
```
OSError: [Errno 98] Address already in use
```

**Solutions:**
- Change the port: `python3 dashboard/run_dashboard.py --reports . --port 8080`
- Find what's using port 5000: `lsof -i :5000`
- Kill the process: `kill $(lsof -t -i:5000)`

### Empty data in charts
- Apply appropriate filters (top of page)
- Check that reports contain the expected benchmark type
- Reload reports: Click "Reload Reports" button in navigation bar
- Check API response: `curl http://localhost:5000/api/results`

### Flask Not Found
```
ModuleNotFoundError: No module named 'flask'
```

**Solution:**
```bash
pip install flask
# or
pip3 install flask
```

### Permission Denied
```bash
chmod +x dashboard/launch_dashboard
chmod +x dashboard/run_dashboard.py
```

### Can't Access from Another Machine
- Dashboard binds to `0.0.0.0` by default (accessible from network)
- Check firewall rules allow port 5000
- Use the server's IP address: `http://10.26.9.237:5000`
- If behind a firewall, use SSH tunnel:
  ```bash
  ssh -L 5000:localhost:5000 user@server
  # Then access at http://localhost:5000 on your local machine
  ```

## Performance Notes

- **Loading Time**: Depends on number of reports and results
- **Memory Usage**: All results are loaded into memory
- **Concurrent Users**: Flask development server (single-threaded)
- **Production Use**: Consider using Gunicorn or uWSGI for production

## Future Enhancements

- [ ] Export charts as images (PNG/SVG)
- [ ] Export filtered data to CSV
- [ ] Historical comparison across date ranges
- [ ] Anomaly detection and alerting
- [ ] Custom metric calculations
- [ ] Dashboard configuration persistence
- [ ] Multi-user support with authentication
- [ ] Real-time streaming updates
- [ ] Database backend for faster queries

## License

[Add license information]

## Contact

[Add contact information]
